# F1 Data Analytics with Azure Databricks & Power BI 🏎️📊

## Project Overview
This project showcases a comprehensive data pipeline for analyzing **Formula 1 racing data** using **Azure Databricks**, **Delta Lake**, and **Power BI**. The solution follows a structured data lakehouse architecture, implementing modern data engineering best practices to ensure efficient data ingestion, transformation, analysis, and reporting.

## [Ergast Developer API](https://ergast.com/mrd/db/#csv)


## What This Project Does:
🚀 **Ingests** F1 race data from the **Ergast API** into **Azure Data Lake Storage (ADLS)**.

🔄 **Transforms** raw data using **Azure Databricks (Apache Spark)** for schema enforcement, partitioning, and optimization.

📈 **Stores** processed data in **Delta Lake** to enable time travel, ACID transactions, and GDPR compliance.

📊 **Visualizes** key insights through **interactive dashboards** in Power BI.

⚙️ **Automates** workflows using **Azure Data Factory (ADF) pipelines** for scheduling and monitoring.

## Tech Stack & Tools Used:
**Cloud & Storage:** Azure Data Lake Storage (ADLS)

**Data Processing:** Azure Databricks (Apache Spark, Delta Lake)

**Data Integration:** Azure Data Factory (ADF)

**Visualization & Reporting:** Power BI

**Data Formats:** Parquet, Delta Lake

**Development & Workflow:** Python, SQL, Databricks Notebooks

## Key Achievements:
✅ Designed a **scalable and production-ready** data pipeline.

✅ Implemented **Delta Lake** to enhance data reliability and performance.

✅ Optimized **data transformation** using **Spark-based processing** in Databricks.

✅ Automated data workflows with **ADF scheduling & monitoring**.

✅ Built interactive **Power BI dashboards** for actionable insights.

## Why This Project Matters:
This project demonstrates end-to-end data engineering with Azure technologies, following industry standards and best practices. It is a valuable resource for those looking to learn data lakehouse architectures, big data processing, and cloud-based analytics.
